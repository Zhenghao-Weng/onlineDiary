[
  {
    "objectID": "week2_Xaringan.html",
    "href": "week2_Xaringan.html",
    "title": "3  Xaringan",
    "section": "",
    "text": "This is a Xaringan presentation on LiDAR:"
  },
  {
    "objectID": "week3_Correction.html#summary",
    "href": "week3_Correction.html#summary",
    "title": "4  Correction",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nThere are four types of correction in RS.\n\nGeometric Correction: This involves the correction of the geometric shape of the image to ensure its accuracy.\nAtmospheric Correction: This adjusts the image to eliminate the impact of the atmosphere on the observed data.\nOrthorectification/Terrain Correction: This corrects the image distortion caused by terrain.\nRadiometric Correction: This adjusts the image data to reflect the true surface radiation values.\n\n\n4.1.1 Dark Object Subtraction\nIn the practical session this week Dark Object Subtraction (DOS) is introduced. DOS is a relatively simple atmospheric correction method used to remove the effects of the atmosphere from satellite imagery, thereby improving the accuracy of the data. The DOS method is based on the logic that the darkest pixel in the satellite image should have zero reflectance; therefore, any value detected can be attributed to the atmospheric effect. By subtracting this value from the rest of the pixels in the image, the impact of the atmosphere can be minimized.\n\nSelecting the Darkest Pixel: First, the darkest pixel in the satellite image needs to be identified. This pixel is assumed to have the minimum reflectance, typically close to zero, but due to atmospheric scattering and other effects, it actually has a non-zero value.\nCalculating Atmospheric Influence: After identifying the darkest pixel, its value (Digital Number, DN) is considered to be caused by atmospheric effects. This value represents the degree of atmospheric influence on the entire image.\nApplying the DOS Formula: Next, the value of the darkest pixel is subtracted from the values of all other pixels in the image. This step aims to remove the atmospheric increment from the measurement value of each pixel, thereby approximating the true surface reflectance.\nConverting to Reflectance: After subtracting the atmospheric influence, the corrected DN values need to be converted to reflectance. This usually involves using satellite-specific conversion formulas that take into account the position of the sun, the distance between the Earth and the sun, and other relevant parameters.\n\n\n\n4.1.2 Image Enhancements\nSeveral techniques for enhancing satellite imagery are covered, including ratioing (e.g., Normalized Difference Vegetation Index - NDVI), filtering, and texture analysis. These methods help emphasize or exaggerate certain features or spectral traits in the imagery.\n\n\n4.1.3 Data Fusion and Principal Component Analysis (PCA)\nThe page touches on the concept of data fusion, combining different raster datasets to enrich the analysis. It also introduces PCA as a method to reduce the dimensionality of data, making it easier to analyze and interpret."
  },
  {
    "objectID": "week3_Correction.html#application",
    "href": "week3_Correction.html#application",
    "title": "4  Correction",
    "section": "4.2 Application",
    "text": "4.2 Application\nDOS is one of the most effective atmospheric correction methods, as the atmospheric offset can be generated from the image itself. In Sean’s research of DOS effectiveness (Sean, Ashty, Ashraf 2015), their analysis indicates that compared to raw data, DOS-corrected imagery performs better in distinguishing wetland areas.\nThe study assesses the effectiveness of the DOS method by comparing the image processing results before and after DOS correction. Two sets of images were used: raw images and DOS-corrected images, along with several water indices to analyze and compare their performance in wetland mapping.\n\n\n\n\n\n(a) The NDWI produced from the raw imagery\n(b) Classified NDWI using the optimal threshold\n(c) The NDWI produced from the DOS imagery\n(d) Classified DOS NDWI using the optimal threshold\n(e) The MNDWI produced from the raw imagery\n(f) Classified MNDWI using the optimal threshold\n(g) The MNDWI produced from the DOS imagery\n(h) Classified DOS MNDWI using the optimal threshold\nThe results show that DOS-corrected images, compared to raw images, exhibit improvements across various accuracy metrics such as overall accuracy, producer’s accuracy, user’s accuracy, and Kappa coefficient. Notably, the MNDWI index demonstrates superior performance on DOS-corrected imagery, achieving an overall accuracy of 98% and a Kappa coefficient exceeding 0.9, indicating that DOS correction significantly enhances the ability to recognize the boundaries between wetland and non-wetland areas. Furthermore, the study found that DOS-corrected images could produce a sharper contrast between wetland and non-wetland areas compared to raw images."
  },
  {
    "objectID": "week3_Correction.html#reflection",
    "href": "week3_Correction.html#reflection",
    "title": "4  Correction",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThe DOS method operates by identifying and subtracting the reflectance values of “dark objects” within an image, which are assumed to have minimal or no reflectance and are primarily affected by atmospheric scattering. These dark objects typically include deep water bodies, cloud shadows, or any other feature with very low reflectance. By subtracting this atmospheric contribution, the DOS method aims to bring the imagery closer to true surface reflectance values, thereby improving the interpretability and accuracy of the data. Researches have verified that DOS has the following advantages:\n\nImproved Accuracy: DOS-corrected imagery shows a marked improvement in distinguishing wetland areas, with significant enhancements in overall accuracy, producer’s accuracy, user’s accuracy, and Kappa coefficient metrics compared to uncorrected raw images.\nEfficiency: DOS is recognized for its simplicity and efficiency, requiring fewer inputs and less complex processing than more robust atmospheric correction methods, such as the Fast Line-of-sight Atmospheric Analysis of Spectral Hypercubes (FLAASH). This makes DOS particularly useful in areas where detailed atmospheric data are unavailable.\nFlexibility in Dark Target Selection: Research indicates that non-ideal dark targets, such as cloud-shadow pixels or the minimum reflectance value within an image, can effectively serve as alternatives to the ideal dark target of optically-deep water. This flexibility ensures the method’s applicability across diverse landscapes where ideal dark objects may not be present."
  },
  {
    "objectID": "week3_Correction.html#references",
    "href": "week3_Correction.html#references",
    "title": "4  Correction",
    "section": "4.4 References",
    "text": "4.4 References\nGilmore, S. and Saleem, A. and Dewan, A. (2015). ‘Effectiveness of DOS (Dark-Object Subtraction) method and water index techniques to map wetlands in a rapidly urbanising megacity with Landsat 8 data’, Proceedings of Research@Locate in conjunction with the annual conference on spatial information in Australia and New Zealand, 1323, pp. 100-108\nWicaksono, P. and Hafizt, M. (2018). ‘Dark target effectiveness for dark‐object subtraction atmospheric correction method on mangrove above‐ground carbon stock mapping’. IET Image Processing, 12(4), pp. 582-587. https://doi.org/10.1049/iet-ipr.2017.0295"
  },
  {
    "objectID": "week4_Policy.html#summary",
    "href": "week4_Policy.html#summary",
    "title": "5  Indonesia’s giant capital city is sinking-A case study of Jakarta’s flooding solution",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nJakarta is the cultural, political and economical heart of Indonesia. This huge cosmopolitan city is with 28 million inhabitants in its metropolitan area, one of the most densely populated cities of South East Asia. However, the Jakarta floods in early 2021 shows how the city’s drainage network can no longer accommodate rainfall, resulting in floods in various locations.\n\n\n\n\n\nAside from drainage issues, there are three key contributing factors to Jakarta’s flooding:\n\nExtreme rainfall: Highly intense and short extreme rainfall is becoming more frequent. Extreme rainfall is a direct result of the climate crisis.\nChanges in land cover: Land cover data from the Ministry of Environment and Forestry (MOEF) for 2000 and 2019 show growing plantation forests by up to 117.7 percent upstream of the river that flows into Jakarta, replacing agricultural lands. Settlement areas have also grown rapidly by 47.4 percent, replacing agricultural lands and green open spaces in central and downstream areas. Green open space only made up 9.8 percent of Jakarta’s area by 2019. This has increased the risk of overflowing rivers and drainage networks due to high volume of runoff, water, not to mention the threat of sedimentation in rivers due to high erosion rates in upstream areas.\nLand subsidence: Land subsidence in Jakarta averages at 12 cm/year. It is even more extreme in the northern coast with a subsidence rate of up to 25cm/year. According to Takagi et al. (2015), subsidence-related flooding will expand by 100.5 km2 by 2050, covering 75 percent of North Jakarta. Building loads and excess groundwater extraction have further accelerated land subsidence. Currently, around 35% of Jakarta residents still use groundwater for their daily needs. As a result, Jakarta’s groundwater level and water storage capacity have continued to decline.\n\n\n5.1.1 Metropolitan Policy\nPetaJakarta.org is a research project led by the SMART Infrastructure Facility, University of Wollongong in collaboration with the Jakarta Emergency Management Agency (BPBD DKI Jakarta) and Twitter Inc. The project enabled Jakarta’s citizens to report the locations of flood events using the social media network Twitter, thereby contributing to a publicly accessible real-time map of flood conditions at PetaJakarta.org. These data were used by BPBD DKI Jakarta to cross-validate formal reports of flooding from traditional data sources, supporting the creation of information for flood assessment, response, and management in real-time.\n\n\n5.1.2 National Policy\nIndonesia’s 2007 Spatial Planning Act is essential to increasing water capacity by requiring all urban areas to set aside 30% of the city land for green space, such as city parks, cemeteries, and green roads. In Jakarta, currently only 10% of the city is green open space, accordingto an analysis by the United Nations Research Institute for Social Development (UNRISD), suggesting a lack ofenforcement for national spatial planning laws at the city level. Jakarta’s most substantial infrastructure response to climate change is the $40 billion National Capital IntegratedCoastal Development (NCICD), which includes the development of a water reservoir, reclamation of land, andconstruction of a seawall along the coast (The Giant Swa Wall of Jakarta), designed to protect the mainland fromtidal flooding.However, the seawall’s projected completion date has been delayed due to stalled negotiations, as the DKI administration is still negotiating with the national Public Works and Public Housing Ministry about which projects will be led by which government bodies (Rahadryan, 2019).\n\n\n5.1.3 International Policy\nOn December 19, 2022, the World Bank’s Board of Executive Directors approved a US$400 million loan to support the Government of Indonesia in protecting an estimated 6.3 million people in cities across Indonesia from damage caused by flooding and in bolstering national flood resilience management. The National Urban Flood Resilience Project (NUFReP) will help cities reduce the flood risk by increasing national and city-level flood risk management capacity and through investments for integrated urban flood risk management. It will also support the government in establishing and operationalizing a national urban flood resilience program. The national urban flood resilience program supported by NUFReP will offer a menu of measures to help cities with different flood and climate risks in an integrated manner. This program will serve as a national umbrella program to help coordinate sources of financing and function as a knowledge hub to help Indonesian cities leverage good practices and continuously advance sector policy, practice, and innovation."
  },
  {
    "objectID": "week4_Policy.html#application",
    "href": "week4_Policy.html#application",
    "title": "5  Indonesia’s giant capital city is sinking-A case study of Jakarta’s flooding solution",
    "section": "5.2 Application",
    "text": "5.2 Application\nSome researches have already verified that RS techniques can be significantly useful in mapping the flood-affected areas, calculating the dimensions of the flooded area and providing critical information for future disaster preparedness (Mutiara, 2019; Dinuke, 2018). Data from Landsat-8 are utilized which providing multispectral images with eight bands at a spatial resolution of 30 meters, a panchromatic band at 15 meters, and two thermal bands at 100 meters. In Indonesia, there is a government agency which is formed for organizing and providingremote sensing data. The Deputy of Remote Sensing Department of National Institute of Aeronautics and Space, Indonesia (LAPAN) has already obtained an authority to provide Landsat data.\nThe integration of Landsat satellite data can positively impact Jakarta’s policy and Indonesia’s policy.\n\n5.2.1 Impact on PetaJakarta.org\n\nData Verification and Supplement: Landsat satellite data can independently verify flood conditions reported by users on Twitter. By comparing the flood extent in satellite imagery with community reports, the actual situation of the flood, including its spread and severity, can be understood more accurately.\nEnhanced Flood Monitoring Capability: Combining community reports with Landsat data can create a more comprehensive flood monitoring system. Landsat’s broad view and high spatiotemporal resolution imagery can capture flood events that Twitter reports might miss, making flood monitoring more comprehensive and timely.\n\n\n\n5.2.2 Impact on NCICD\n\nPlanning and Optimization of Embankment Location: Landsat data can provide detailed terrain and land cover information of river basins, helping decision-makers more accurately plan the location and design of embankments. By analyzing changes in the land surface before and after floods, areas frequently affected by flooding can be identified, guiding the optimal layout of embankments.\nEnvironmental Impact Assessment: Before the construction of embankments, Landsat satellite data can be used to assess the potential environmental impact of the plan. By monitoring changes in vegetation cover, hydrological conditions, and surface temperature of the construction area, the project’s impact on ecosystems can be predicted, providing a basis for formulating mitigation measures.\nProject Supervision and Effectiveness Evaluation: After the construction of embankments, Landsat data can be used to monitor the long-term effects and maintenance status of the project. By regularly comparing satellite images of the flood control area, the effectiveness of the embankments in flood prevention and potential issues can be assessed, providing information support for subsequent improvements."
  },
  {
    "objectID": "week4_Policy.html#reflection",
    "href": "week4_Policy.html#reflection",
    "title": "5  Indonesia’s giant capital city is sinking-A case study of Jakarta’s flooding solution",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nFrom the aforementioned case analysis, policies addressing urban issues are usually comprised of different levels. International policies tend to be comprehensive and broad, outlining general development directions or involving resource assistance from developed countries to others. Thus, international policies focus on the determination of overall directions and the allocation of resources. National policies typically further analyze problems within a country and propose a feasible plan. However, these plans usually take a long time to complete but have significant effectiveness in solving problems. Therefore, national policies focus on long-term effects. Urban policies often complement national policies, achieving some effects with smaller investments, but many times they cannot fundamentally solve problems. Hence, urban policies focus on short-term effects. In the aforementioned case, the application of RS data can enhance the effectiveness of urban policies, providing validation and supplement for PetaJakarta.org. It can also optimize solutions within national policies, improving the construction locations of embankments; at the same time, it minimizes losses before the completion of national policies by predicting and assessing disasters for floods occurring during riverside construction. The success of national policy plans can also be promoted to other countries through international policies as a model. Other countries affected by flooding can gain experience from Jakarta’s case in RS data application, the public online flood reporting community, and embankment construction projects, fostering global collective development."
  },
  {
    "objectID": "week4_Policy.html#references",
    "href": "week4_Policy.html#references",
    "title": "5  Indonesia’s giant capital city is sinking-A case study of Jakarta’s flooding solution",
    "section": "5.4 References",
    "text": "5.4 References\nWals, Jorian. (2015). ‘Flood Resilient Cities - An Jakarta Case Study’. 10.13140/RG.2.1.3463.9840.\nHiroshi Takagi, Miguel Esteban, Takahito Mikami, Daisuke Fujii. (2016) ‘Projection of coastal floods in 2050 Jakarta’, Urban Climate 17, pp. 135-145, https://doi.org/10.1016/j.uclim.2016.05.003.\nTomas Holderness & Etienne Turpin, ‘White Paper ‑ PetaJakarta.org:\nAssessing the Role of Social Media for Civic Co‑Management During Monsoon Flooding\nin Jakarta, Indonesia’, SMART Infrastructure Facility, University of Wollongong\nRahadryan, A. (2019). Jakarta infrastructure: NCICD sea wall project delayed until 2022. PWC Indonesia.\nGeorge, Elisha, et al. (2020). ‘JAKARTA POLICY BRIEF’, CITY RESILIENCY AND CLIMATE CHANGE: A REPORT FROM THE INTER-POLICY SCHOOL SUMMIT 2020, pp. 27–32, https://www.jstor.org/stable/resrep42654.7\nSyifa, Mutiara, et al. (2019). ’Flood Mapping Using Remote Sensing Imagery and Artificial Intelligence Techniques: A Case Study in Brumadinho, Brazil.” Journal of Coastal Research, pp. 197–204. JSTOR, https://www.jstor.org/stable/26778954\nMunasinghe, Dinuke, Sagy Cohen, Yu-Fen Huang, Yin-Phan Tsang, Jiaqi Zhang, and Zheng Fang, (2018). ‘Intercomparison of Satellite Remote Sensing-Based Flood Inundation Mapping Techniques’. Journal of the American Water Resources Association (JAWRA) 54(4), pp. 834–846. https://doi-org.libproxy.ucl.ac.uk/10.1111/1752-1688.12626"
  },
  {
    "objectID": "week8_Classification2.html#summary",
    "href": "week8_Classification2.html#summary",
    "title": "8  Classification 2",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Sub-pixel Analysis:\nSpectral Unmixing: This technique is used to estimate the fraction of land cover types within a pixel by comparing the pixel’s spectral signature to those of “spectrally pure” end members. Two main approaches are discussed:\n\nDefining end members directly through known values or selecting points on the image that represent pure land cover types.\nUsing training data to average the spectral signatures of land cover types and create end members.\n\nThe unmix() function in GEE is then used to apply spectral unmixing to the image, producing a new image that represents the fractional composition of each land cover type within the pixels.\n\n\n8.1.2 Accuracy Assessment for Sub-pixel Analysis:\nThe webpage acknowledges the challenge of assessing accuracy in sub-pixel analysis due to the continuous nature of the output (fractions of land cover types). Two main approaches to address this challenge are mentioned:\n\nHardening the sub-pixel image by classifying each pixel based on the dominant land cover fraction (e.g., assigning a pixel to a land cover class if more than 50% of the pixel is composed of that class).\nA more involved method that requires overlaying high-resolution imagery over Landsat pixels, digitizing high-resolution data within each pixel, and comparing the results.\n\n\n\n8.1.3 Object-based Image Analysis (OBIA):\nImage Gradient and Spectral Gradient: Initial steps in OBIA involve identifying changes in intensity or color in an image to group pixels into objects.\nSuper Pixels and Clustering: Techniques like k-means clustering and Simple Non-Iterative Clustering (SNIC) are introduced to segment the image into super pixels or objects based on spectral and spatial similarities.\n\nK-means clustering groups pixels into clusters with similar spectral properties.\nSNIC performs clustering without iterative processes, considering both color and spatial proximity to create more defined objects.\n\nThe output of these clustering methods can then be used to extract additional information, such as standard deviation or NDVI for each object, which can assist in further classification or analysis.\n\n\n8.1.4 Classification of Objects:\nIt involves selecting training data (points or polygons) representing different land cover types, extracting features from the objects, and then training a classifier (e.g., CART) using this training data. The classified image is then visualized in GEE, showing the distribution of land cover types across the study area."
  },
  {
    "objectID": "week8_Classification2.html#application",
    "href": "week8_Classification2.html#application",
    "title": "8  Classification 2",
    "section": "8.2 Application",
    "text": "8.2 Application\nTraditionally, the accuracy of classifications is assessed using a confusion matrix, which provides a quantitative measure of classification performance but lacks spatial distribution information of errors. In their research, Alexis, et al. aims to address these limitations by incorporating geographically weighted approaches to model spatial variations in the accuracy of both Boolean and fuzzy land cover classifications.\n\n\n\n\n\nAlso, Mitchell, et al. review in their research that traditional accuracy metrics often overlook variance, which is crucial for making informed decisions based on map accuracy. The study compares a single split of data into training and test sets against a resampling framework where classification and accuracy assessment are repeated multiple times. The analysis, conducted using a simple vegetation mapping example with maximum likelihood and random forest classifiers, explores the impact of resampling and stratification design on accuracy metrics and class area estimates."
  },
  {
    "objectID": "week8_Classification2.html#reflection",
    "href": "week8_Classification2.html#reflection",
    "title": "8  Classification 2",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nIt is evident that the processing and analysis of remote sensing data are moving towards higher accuracy, efficiency, and automation. The accuracy and efficiency of remote sensing classification have significantly improved by utilizing advanced algorithms such as machine learning and deep learning. These algorithms are capable of processing and analyzing large-scale remote sensing data, extracting complex surface features, and thereby achieving more accurate identification of land cover types and monitoring changes.\nLooking forward, the future development of integrating classification algorithms with remote sensing will likely focus on further methodological innovations, particularly in improving accuracy assessment techniques. The trend is towards more dynamic, spatially-aware models that can better account for the complexity and variability of the earth’s surface as captured by remote sensing technologies. As machine learning and deep learning algorithms continue to evolve, we can anticipate more sophisticated approaches for modeling and evaluating the accuracy of remote sensing classifications. This will likely involve integrating multi-source data, enhancing the resolution and quality of remote sensing inputs, and leveraging big data and cloud computing platforms for more efficient data processing and analysis. Together, these advancements will provide stronger support for global environmental monitoring efforts, contributing significantly to our understanding and management of natural and human-modified landscapes."
  },
  {
    "objectID": "week8_Classification2.html#reference",
    "href": "week8_Classification2.html#reference",
    "title": "8  Classification 2",
    "section": "8.4 Reference",
    "text": "8.4 Reference\nMitchell B. Lyons, David A. Keith, Stuart R. Phinn, Tanya J. Mason, Jane Elith, (2018.) ‘A comparison of resampling methods for remote sensing classification and accuracy assessment’, Remote Sensing of Environment 208, pp. 145-153, doi: 10.1016/j.rse.2018.02.026.\nAlexis Comber, Peter Fisher, Chris Brunsdon, Abdulhakim Khmag, (2012.) ‘Spatial analysis of remote sensing image classification accuracy’, Remote Sensing of Environment 127, pp. 237-246, doi: 10.1016/j.rse.2012.09.005."
  },
  {
    "objectID": "week6_GEE.html#summary",
    "href": "week6_GEE.html#summary",
    "title": "6  Introduction to GEE",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nGEE is a cloud-based platform for planetary-scale environmental data analysis that allows users to access and analyze vast amounts of geospatial data stored on Google’s servers. The platform uses JavaScript for data analysis, and the webpage provides a brief introduction to the necessary JavaScript concepts for using GEE.\n\n6.1.1 Common workflow of GEE\n\n6.1.1.1 Creating Points and Centering the Map:\n\nCreate a geographic point using coordinates and then center the map on this point. ee.Geometry.Point([longitude, latitude])\nCenters the map on this point with a specified zoom level using Map.centerObject(point, zoomLevel).\n\n\n\n6.1.1.2 Load Landsat Data:\n\nFilter the Landsat dataset by date, using ee.ImageCollection('LANDSAT/LC09/C02/T1_L2').filterDate('start-date', 'end-date'), to load images from a specific time period.\nDisplay the Landsat data on the map and specify which bands to visualize Map.addLayer(dataset, {bands: [\"SR_B4\", \"SR_B3\", \"SR_B2\"]}, \"Landsat 9\")\n\n\n\n6.1.1.3 Filter and Display Images:\n\nMore advanced filtering options, including filtering by date range, geographic bounds (using the previously created point or polygon), and cloud cover.\n\n\n\n6.1.1.4 Deal with Multiple Images:\n\nSelect a single image from the collection, reduce the collection to a single representative image using statistical reducers (e.g., median), and mosaic images to create a composite image."
  },
  {
    "objectID": "week6_GEE.html#application",
    "href": "week6_GEE.html#application",
    "title": "6  Introduction to GEE",
    "section": "6.2 Application",
    "text": "6.2 Application\nAccording to Meisam’s comprehensive review, GEE is a cloud computing platform developed by Google to address the challenges of analyzing big data from remote sensing systems. It offers a solution by facilitating the processing of large geospatial data sets over extensive areas and long periods, making it a powerful tool for environmental monitoring and analysis. GEE has been particularly useful in applications such as land cover/land use classification, hydrology, urban planning, natural disaster analysis, climate studies, and image processing.\n\nIt is capable of handling the vast amount of data from satellites like Landsat and Sentinel, and employs advanced algorithms, including supervised machine learning techniques like Random Forest for image classification tasks."
  },
  {
    "objectID": "week6_GEE.html#reflection",
    "href": "week6_GEE.html#reflection",
    "title": "6  Introduction to GEE",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nGEE and R are two powerful tools in processing remote sensing data. With its cloud computing strength and vast built-in datasets, GEE is particularly suitable for large-scale remote sensing data analysis and environmental monitoring. Meanwhile, R offers advantages in flexibility and depth for data analysis, ideal for research requiring complex data processing and customized analysis.\nGEE Pros:\n\nCloud Computing Platform: GEE offers powerful cloud computing capabilities, allowing for the processing of large-scale remote sensing datasets without the need for high-performance personal computers.\nExtensive Public Datasets: GEE integrates a vast array of public remote sensing datasets, including Landsat, Sentinel series, etc., enabling direct online processing without the need for downloads.\nEfficient Data Processing: GEE has optimized data processing workflows, facilitating rapid data analysis and image processing, especially suited for extensive area and long-term environmental monitoring.\n\nGEE Cons:\n\nData Privacy: Since data is stored on Google’s servers, there might be concerns for users or institutions with specific data privacy requirements.\nProcessing Capability Limitations: Although GEE provides robust cloud computing power, some particularly complex custom processing workflows may encounter performance bottlenecks.\n\nR Pros:\n\nFlexibility: R is a software for statistical computing and graphics, offering numerous packages and functions, particularly powerful in data analysis and statistical inference.\nOpen Source and Free: R is open-source with active community support, providing abundant resources and documentation for learning and use.\nSuitable for Custom Analysis: R offers greater flexibility and control for users needing complex data analysis and customized processing.\n\nR Cons:\n\nData Scale Limitations: Relative to GEE’s cloud computing platform, R’s data processing capabilities are limited to the user’s computer performance, making it unsuitable for extremely large datasets.\nData Preparation: Users need to download and manage remote sensing data themselves, which, compared to GEE’s direct online processing, increases the workload for data preparation."
  },
  {
    "objectID": "week6_GEE.html#reference",
    "href": "week6_GEE.html#reference",
    "title": "6  Introduction to GEE",
    "section": "6.4 Reference",
    "text": "6.4 Reference\nM. Amani et al. (2020). ‘Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review,’ IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 13, pp. 5326-5350, doi: 10.1109/JSTARS.2020.3021052."
  },
  {
    "objectID": "week7_Classification1.html#summary",
    "href": "week7_Classification1.html#summary",
    "title": "7  Classification 1",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Common workflow\nSelect Training Data: In GEE, select training data by clicking the polygon symbol and adding polygons for the land cover types you wish to classify. Add a new layer for each different land cover type. These polygons then need to be merged into a feature collection.\nSet Classifier Context: Next, set some context for the classifier, such as which bands to use and the name of the classification property.\nExtract Training Area Data: Then, extract data from the training areas to prepare for classification training.\nTrain Classifier: Train the classifier using the CART algorithm. After training, you can print some information about the classifier, such as maximum depth, variable importance, and the number of nodes.\nApply Classifier: Finally, apply the trained classifier to the image, and then plot the output result on the map.\n\n\n7.1.2 Split train & test data\nTraditional Training and Testing Split Method\nIn this method, the process begins by adding a column of random numbers to the training dataset. These random numbers are used to divide the data into training and testing sets.\nAdd Random Column: Add a column of random numbers to the polygon feature collection. These random numbers are used for subsequent data splitting.\nSplit Data: Based on the values in the random number column, divide the data into training and testing sets. For example, a threshold (such as 0.7) can be set, where data with values below this threshold are used as the training set, and data with values equal to or greater than this threshold are used as the testing set.\nSampling and Validation: Sample from the image for both the training and testing sets, and use these samples to train the classifier. Then, use the testing set to validate the accuracy of the classifier.\nPixel-Based Splitting Method\nThis method is more detailed, dividing pixels within each category randomly to generate training and testing sets.\nGenerate Random Points: For each land cover type, generate a certain number of random points and assign category labels to these points.\nAssign Random Numbers: Assign random numbers to these points to divide them into training and testing sets.\nCreate Training and Validation Samples: Based on the assigned random numbers, divide the points into training samples and validation samples. Then, sample from the image for these samples to obtain training and validation data.\nTrain and Validate Classifier: Train the classifier using the training data, and then use the validation data to assess the classifier’s performance. This can be done by calculating error matrices, overall accuracy, and user accuracy, among other metrics."
  },
  {
    "objectID": "week7_Classification1.html#application",
    "href": "week7_Classification1.html#application",
    "title": "7  Classification 1",
    "section": "7.2 Application",
    "text": "7.2 Application\nIn a research on crop cultivation identification, the authors use a two-step process for crop classification (Wen, 2023). First, they employ the Canny edge detector combined with the Otsu automatic thresholding algorithm on time-series Sentinel-2 images to delineate field edges accurately. This step is crucial for minimizing classification errors caused by mixed pixels at the boundaries of cropland parcels. Second, they apply the Random Forest (RF) algorithm to classify crops based on phenological information extracted from time-series images of both Landsat and Sentinel-2. The RF model, configured with 500 trees, utilizes the yearly time series of Normalized Difference Vegetation Index (NDVI) and Land Surface Water Index (LSWI) as input variables. This phenology-based approach allows for the differentiation of crop types across the study area, taking advantage of the distinct seasonal growth patterns of different crops."
  },
  {
    "objectID": "week7_Classification1.html#reflection",
    "href": "week7_Classification1.html#reflection",
    "title": "7  Classification 1",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThe integration of remote sensing technology with classification methods, especially machine learning and deep learning algorithms, has brought revolutionary changes to fields such as environmental monitoring, agriculture, and urban planning. This integration leverages the richness and spatiotemporal information of remote sensing data to achieve precise classification and monitoring of land surface characteristics, improving the efficiency and accuracy of data processing.\n\nImproved Accuracy and Efficiency: Machine learning and deep learning algorithms can process vast amounts of remote sensing data, improving the accuracy and efficiency of classification. This is particularly important for monitoring large-scale land surface changes.\nMulti-source Data Fusion: The combination of different sources and types of remote sensing data (e.g., optical, radar, multi-temporal data) through optimized algorithmic processing provides more comprehensive and accurate monitoring results.\nDynamic Monitoring and Analysis: Using time series remote sensing data and classification algorithms enables dynamic monitoring of land surface changes and analysis of long-term trends, such as crop growth monitoring and urban expansion analysis."
  },
  {
    "objectID": "week7_Classification1.html#reference",
    "href": "week7_Classification1.html#reference",
    "title": "7  Classification 1",
    "section": "7.4 Reference",
    "text": "7.4 Reference\nWen, Z., Jiang, D., Jing, Ye, & Liu, G. (2023). ‘Remote sensing classification approach to large-scale crop cultivation identification: A case study of the Aral Sea Basin’. Transactions in GIS, 27, pp. 2278–2296. doi: 10.1111/tgis.13120"
  }
]